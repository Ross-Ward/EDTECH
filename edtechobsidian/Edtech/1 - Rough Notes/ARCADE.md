## **"ARCADE: Evaluating AI-Assisted Low-Code Design's Impact on Coding Fluency in Collaborative Software Projects"**

**What to study:**

- Coding fluency metrics (pre/post)
- Resource management patterns
- Token/API usage efficiency
- Team communication quality

**Why:**

- Low-code AI tools may reduce coding practice
- Agentic design patterns could stabilize learning outcomes
- Resource sharing forces strategic thinking

### **What this study investigates**

- How **ARCADE** (Assisted Realtime Collaborative AI-Driven Design Environment) affects:
    - Individual coding fluency
    - Team resource allocation
    - Communication patterns
    - Design decision quality

### **Why this matters**

- Students may lose fundamental coding skills using AI assistants
- Shared resource constraints mirror real-world API limits
- Agentic patterns could scaffold proper tool usage

### **Relevant Theories**

- **Cognitive Load Theory** (AI reducing/shifting cognitive work)
- **Constructivism** (learning through constrained doing)
- **Distributed Cognition** (team + AI as cognitive system)
- **Agentic Design Patterns** (structured AI interaction)

### **Core Research Question**

Do low-code AI-assisted design tools affect coding fluency negatively or positively when mediated by agentic design patterns and resource constraints?

### **Study Design**

**Groups:**
- Control: Traditional coding (VS Code, GitHub)
- Experimental: ARCADE with shared token pool

**Resource Constraint:**
- Each team gets limited API tokens
- Members must coordinate usage
- Forces strategic AI assistance decisions

**Branches & Issues:**
- Each member owns a project branch
- Assigned specific issues/features
- Must integrate through collaboration

|Construct|Metric / Instrument|
|---|---|
|Coding Fluency|Pre/post coding assessments, code quality rubric|
|Resource Management|Token usage logs, allocation patterns|
|Communication|Git commits, PR comments, team chat analysis|
|Design Quality|Architecture review, pattern application|
|Learning Outcomes|Concept tests, reflection journals|

### **Methodology**

- **Quasi-experimental** (4-6 week group project)
- Mixed methods (quantitative + qualitative)
- Weekly fluency checkpoints
- Post-project interviews

### **Agentic Design Pattern Integration**

- Prompt chaining for complex tasks
- Reflection loops before code generation
- Tool use constraints (when to use AI vs manual)
- Planning patterns for resource allocation

**Hypothesis:**

Constrained AI assistance + agentic patterns maintains/improves coding fluency while accelerating development.

---

## **Extended Literature Foundation**

### **AI-Assisted Programming in Education (2024-2025)**

Recent research shows AI coding tools are "deeply integrated into the software lifecycle automating up to 30% of coding tasks" by 2025 (Technostacks, 2025). However, concerns emerge about **coding fluency degradation** when students over-rely on AI assistants.

- **IEEE Spectrum (2024)**: Educators now require students to "work in groups and submit a video explaining how their code works" to combat AI dependency
- **MDPI Education Sciences (2024)**: Study in first-semester programming found AI tools have "positive and negative effects on students' learning experiences and their ability to develop essential programming skills"
- **ScienceDirect (2025)**: Systematic review of 119 papers (2012-2024) on AI/ML in programming education reveals need for balanced integration

### **Low-Code Platforms in Collaborative Learning**

Low-code platforms are "democratizing the creation process" (DEVOPSdigest, 2024) but academic research lags behind industry adoption:

- **Educational institutions use low-code platforms** for student management and e-learning (Medium, 2024)
- **Collaboration between professional and citizen developers** becoming standard practice (SlashDev, 2024)
- **Live collaborative development support** enables geographically distributed teams (Software and Systems Modeling, 2021)

### **Agentic Design Patterns as Pedagogical Scaffolds**

From Antonio Gulli's framework, key patterns applicable to education:

1. **Prompt Chaining**: Breaking complex tasks into sequential steps
2. **Reflection**: Iterative self-assessment loops before code generation
3. **Tool Use**: Strategic decision-making about when to use AI vs manual coding
4. **Resource-Aware Optimization**: Managing constrained resources (tokens, API calls)
5. **Human-in-the-Loop**: Maintaining human oversight in critical decisions
6. **Planning**: Goal-based task decomposition and milestone tracking

### **Resource Constraints as Learning Mechanism**

"Educational tools enable educators and students to regulate learning outcomes through structured adaptive frameworks" (Empowering Students Through Self-Regulated Scaffolding, 2024). Shared resource pools force:

- **Strategic thinking** about AI tool usage
- **Team communication** for resource allocation
- **Metacognitive awareness** of when AI helps vs hinders learning

---

## **Theoretical Framework**

### **Cognitive Load Theory (Sweller, 1988)**

- **Intrinsic Load**: Complexity of coding tasks
- **Extraneous Load**: Interface friction, tool confusion
- **Germane Load**: Deep learning through problem-solving

**Application**: ARCADE reduces extraneous load (AI handles boilerplate) while maintaining germane load (students make architectural decisions)

### **Constructivism (Piaget, Vygotsky)**

Learning through **constrained doing** - students construct knowledge by:
- Making strategic choices under resource limits
- Collaborating within shared token budgets
- Reflecting on AI assistance effectiveness

### **Distributed Cognition (Hutchins, 1995)**

Team + AI system as **cognitive unit**:
- AI handles syntax and documentation lookup
- Humans handle design decisions and integration
- Shared resources require explicit coordination

### **Self-Regulated Learning (Zimmerman, 2002)**

Agentic patterns scaffold:
- **Forethought**: Planning token usage strategically
- **Performance**: Monitoring AI assistance quality
- **Self-reflection**: Evaluating learning outcomes

---

## **ARCADE System Architecture**

### **Core Components**

1. **Shared Token Pool**
   - Team allocation: 10,000 tokens/week
   - Individual tracking dashboard
   - Usage analytics and recommendations

2. **Branch-Based Workflow**
   - Each member owns feature branch
   - AI assistance logged per branch
   - Integration requires manual code review

3. **Agentic Pattern Integration**
   - **Reflection prompts** before AI generation
   - **Planning templates** for task breakdown
   - **Tool use guidelines** (when to use AI)
   - **Human-in-loop** checkpoints

4. **Fluency Checkpoints**
   - Weekly coding assessments (no AI)
   - Concept understanding tests
   - Code review participation metrics

### **Resource Management Dashboard**

```
Team Token Budget: 10,000/week
├── Member A: 2,500 used (25%)
├── Member B: 3,200 used (32%)
├── Member C: 1,800 used (18%)
└── Reserve: 2,500 remaining

Recommendations:
- Member B: High usage on boilerplate - consider templates
- Team: 40% tokens on debugging - review testing strategy
```

---

## **Detailed Methodology**

### **Participants**

- **N = 60** final-year CS students
- **Control Group (n=30)**: Traditional VS Code + GitHub
- **Experimental Group (n=30)**: ARCADE with shared tokens
- **Duration**: 6-week group project (3-4 students per team)

### **Project Structure**

**Week 1-2**: Planning & Architecture
- Define features and assign branches
- Establish token allocation strategy
- Complete baseline fluency assessment

**Week 3-5**: Development
- Weekly fluency checkpoints (no AI)
- Token usage monitoring
- Peer code reviews

**Week 6**: Integration & Evaluation
- Final fluency assessment
- Project quality review
- Qualitative interviews

### **Data Collection Instruments**

| Measure | Instrument | Frequency |
|---------|-----------|-----------|
| Coding Fluency | Timed coding challenges (no AI) | Pre, Weekly, Post |
| Code Quality | Rubric: maintainability, correctness, architecture | Weekly reviews |
| Token Usage | System logs: prompts, responses, acceptance rate | Continuous |
| Communication | Git commits, PR comments, Slack analysis | Continuous |
| Team Dynamics | Collaboration survey (Likert scale) | Weekly |
| Cognitive Load | NASA-TLX | Post-sprint |
| Self-Regulation | Metacognitive Awareness Inventory | Pre, Post |
| Perceptions | TAM-based survey + interviews | Post |

### **Coding Fluency Assessment**

**Pre/Post Test** (60 minutes, no AI):
1. Debug broken code (3 bugs)
2. Implement algorithm from description
3. Refactor legacy code
4. Write unit tests

**Weekly Checkpoints** (20 minutes):
- Explain code snippet functionality
- Identify design pattern usage
- Propose optimization strategy

---

## **Expected Findings**

### **Hypothesis 1: Maintained Fluency**
Experimental group maintains coding fluency scores (±5% of control) while completing projects 20-30% faster

### **Hypothesis 2: Strategic AI Use**
Resource constraints lead to:
- Higher quality prompts (measured by acceptance rate)
- More selective AI usage (complex tasks vs simple)
- Better metacognitive awareness

### **Hypothesis 3: Enhanced Collaboration**
Shared resources increase:
- Communication frequency (Git/Slack metrics)
- Code review quality (review depth scores)
- Team coordination (survey responses)

### **Hypothesis 4: Pattern Adoption**
Students internalize agentic patterns:
- Reflection before generation (logged behavior)
- Planning-first approach (task breakdown quality)
- Human-in-loop verification (error catch rate)

---

## **Pedagogical Implications**

### **For Educators**

1. **Scaffold AI tool usage** through resource constraints
2. **Teach agentic patterns** as metacognitive strategies
3. **Maintain fluency checkpoints** to prevent skill atrophy
4. **Foster team resource management** as professional skill

### **For Students**

1. **Strategic thinking** about tool usage
2. **Metacognitive awareness** of learning process
3. **Collaboration skills** under constraints
4. **Professional practices** (code review, documentation)

### **For Institutions**

1. **Curriculum integration** of AI-assisted development
2. **Assessment redesign** for AI-augmented work
3. **Infrastructure** for token management systems
4. **Policy development** on AI tool usage

---

## **Ethical Considerations**

### **Academic Integrity**

- Clear guidelines on AI usage boundaries
- Fluency assessments without AI access
- Code explanation requirements
- Attribution of AI-generated code

### **Equity & Access**

- Equal token allocation per team
- No external AI tool advantages
- Accessible interface design
- Support for diverse learning needs

### **Data Privacy**

- Anonymized usage logs
- Opt-in research participation
- Secure token management
- GDPR/FERPA compliance

### **Skill Development**

- Balance AI assistance with fundamental learning
- Prevent over-reliance through constraints
- Maintain human decision-making primacy
- Foster critical evaluation of AI outputs

---

## **Future Research Directions**

1. **Longitudinal Studies**: Track coding fluency 6-12 months post-graduation
2. **Industry Transfer**: Do ARCADE skills translate to professional settings?
3. **Pattern Variations**: Which agentic patterns most effective for learning?
4. **Optimal Constraints**: What token limits maximize learning outcomes?
5. **Cross-Disciplinary**: Apply ARCADE to data science, web dev, mobile dev
6. **AI Evolution**: How do findings change with GPT-5, Claude 4, etc?

---

## **References**

### **Recent Research (2024-2025)**

- IEEE Spectrum. (2024). AI Copilots Are Changing How Coding Is Taught. https://spectrum.ieee.org/ai-coding
- MDPI. (2024). The Good and Bad of AI Tools in Novice Programming Education. Education Sciences, 14(10), 1089.
- ScienceDirect. (2025). Artificial intelligence in computer programming education: A systematic literature review. Computers and Education Open.
- Technostacks. (2025). How AI Is Revolutionizing Coding & Developer Productivity in 2025.

### **Low-Code & Collaboration**

- DEVOPSdigest. (2024). 2024 Low-Code/No-Code Predictions.
- Medium. (2024). Top Trends in Low-Code Development for 2024.
- SlashDev. (2024). Low-Code and No-Code Development: A 2024 Overview.
- Software and Systems Modeling. (2021). Low-code development and model-driven engineering.

### **Foundational Theory**

- Gulli, A. (2024). Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems.
- Sweller, J. (1988). Cognitive load during problem solving. Cognitive Science, 12(2), 257-285.
- Zimmerman, B. J. (2002). Becoming a self-regulated learner. Theory Into Practice, 41(2), 64-70.

### **Educational Technology**

- Ellucian. (2023). Maximizing Student Success with Intelligent Course Recommendations.
- Higher Education Authority. (2024). Progression and retention in Irish higher education.
- Washington University. (2025). AI Tool Helps Make Trustworthy, Explainable Scheduling Decisions.
