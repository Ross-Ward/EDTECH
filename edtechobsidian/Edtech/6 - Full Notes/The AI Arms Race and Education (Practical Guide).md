

_This companion summary is written in accessible language for educators, students, and tech practitioners._

## What Is the “AI Arms Race”?

Imagine countries competing to build the most powerful robots or smart weapons. That’s the idea of an AI arms race: nations race to use artificial intelligence (AI) to make their armies stronger. Unlike past arms races (tanks, bombs, nuclear weapons), AI is built mostly by commercial tech companies. So when we talk about AI in war, we must also talk about Big Tech firms.

 

Major tech companies have **two faces**: consumer products (social media, search, apps) and defense contracts. In recent years, many firms have started selling their advanced AI to the military. They do this through software contracts, partnerships with defense startups, or by releasing open-source models that can be adapted for any use. Because AI tools (like language models or computer vision software) are so flexible, they can serve both everyday users _and_ soldiers at the same time.

## Who’s Involved?

- **Palantir:** This U.S. company started out doing police and spy work. Now it openly builds AI for armies. For example, Palantir’s new _AI Platform (AIP)_ is used in Ukraine and by U.S. forces. It takes battlefield data (maps, drone cameras, sensors) and uses AI to suggest tactics, track targets, or predict enemy moves​[aimresearch.co](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=That%E2%80%99s%20not%20hyperbole,by%20Google%20after%20employee%20protests). Palantir even calls AI a _weapon_. Its CEO said AI “will be used to kill people.” Back in the U.S., Palantir also sold an AI system to ICE (immigration enforcement) that flags immigrants based on faces and social ties​[aimresearch.co](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=In%202023%2C%20Immigration%20and%20Customs,one%20ICE%20official%20described%20it). Critics warn this turns people into numbers in a “pre-crime” system​[aimresearch.co](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=Civil%20liberties%20groups%20call%20it,%E2%80%9D).
    
- **Meta (Facebook):** Meta created the Llama series of AI models and released them publicly. These models are very capable at understanding and generating text. Reuters found Chinese military researchers **used Meta’s Llama** to create a new tool called “ChatBIT” for battlefield intelligence​[reuters.com](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=Nov%201%20%28Reuters%29%20,three%20academic%20papers%20and%20analysts). Meta’s license says “no military or espionage,” but once the code is out, it’s hard to stop misuse​[reuters.com](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=However%2C%20because%20Meta%27s%20models%20are,ways%20of%20enforcing%20those%20provisions). After this became known, Meta made Llama _available to U.S. defense agencies_ – reversing its own rule​[theguardian.com](https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai#:~:text=Meta%20%20announced%20Monday%20that,wing%20of%20the%20Chinese%20government)​[theguardian.com](https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai#:~:text=Meta%E2%80%99s%20policies%20typically%20prohibit%20the,the%20UK%2C%20Canada%2C%20Australia%20and). Meta’s argument: U.S. troops also need the best AI to keep up with rivals.
    
- **OpenAI (ChatGPT’s creator):** Initially OpenAI banned military use of ChatGPT. In early 2024, it quietly changed this. At Davos (Jan 2024), OpenAI announced it would help the Pentagon develop cybersecurity tools using its AI​[govconwire.com](https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/#:~:text=At%20the%20World%20Economic%20Forum,based%20cybersecurity%20technology). In fact, OpenAI is working with Anduril, a defense startup, to power drone-swarming systems. LLMs (like GPT) are plugged into Anduril’s air defense interface, helping translate human commands into actions for drones​[wired.com](https://www.wired.com/story/openai-anduril-defense/#:~:text=OpenAI%E2%80%99s%20AI%20models%20will%20be,pressure%20situations%2C%E2%80%9D%20he%20said)​[wired.com](https://www.wired.com/story/openai-anduril-defense/#:~:text=Anduril%20is%20developing%20an%20advanced,language%20models%20for%20testing%20purposes). OpenAI now says its AI will make air-defense smarter, scanning for drone threats “more quickly and accurately”​[wired.com](https://www.wired.com/story/openai-anduril-defense/#:~:text=OpenAI%E2%80%99s%20AI%20models%20will%20be,pressure%20situations%2C%E2%80%9D%20he%20said). This surprised some OpenAI staff, since until 2024 ChatGPT had a military-use ban. But now they justify it as serving U.S. security and “democratic values.”
    
- **Microsoft and Google:** These giants provide the cloud computing and AI models that militaries use. For instance, Israel’s military uses Microsoft’s Azure and OpenAI tools to sift through captured enemy communications for targeting​[apnews.com](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Israeli%20military%20uses%20Microsoft,targeting%20systems%20and%20vice%20versa)​[apnews.com](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Microsoft%20data%20AP%20reviewed,racial%20commentary%20and%20violent%20rhetoric). A recent investigation found Israeli use of Azure spiked 200-fold during the Gaza conflict​[apnews.com](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Israeli%20military%E2%80%99s%20usage%20of,months%20of%20the%20war%20alone). Microsoft even signed a $133M contract directly with Israel’s defense ministry​[apnews.com](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20AP%20also%20interviewed%2014,and%20Israel%E2%80%99s%20Ministry%20of%20Defense). Google teamed up with Amazon in “Project Nimbus,” a $1.2B cloud deal to give Israeli agencies (including military) AI services​[en.wikipedia.org](https://en.wikipedia.org/wiki/Project_Nimbus#:~:text=The%20Israeli%20Finance%20Ministry%20,finance%2C%20healthcare). Google’s AI tools (face recognition, image analysis) are said to be tested in that context​[en.wikipedia.org](https://en.wikipedia.org/wiki/Project_Nimbus#:~:text=Although%20Project%20Nimbus%27%20specific%20mission,1). Notably, Google employees protested when Google tried to do a similar AI-for-war project (Maven) with the U.S. military in 2018​[wired.com](https://www.wired.com/story/openai-anduril-defense/#:~:text=A%20few%20years%20ago%2C%20many,backed%20out%20of%20the%20project). That protest is a high-water mark of tech opposition to military AI, but many companies later warmed to it after geopolitical shifts.
    
- **Huawei and Baidu (China):** China officially blends civilian and military tech, so big Chinese tech firms contribute too. Huawei, best known for phones and 5G, actually worked on many AI projects with China’s army. In 2019, Bloomberg reported Huawei staff co-authored at least 10 AI research papers with PLA scientists, on tasks like analyzing satellite imagery​[qz.com](https://qz.com/1653915/bloomberg-huawei-staff-did-ai-research-with-chinas-military#:~:text=Some%20employees%20of%20Chinese%20tech,satellite%20images%2C%20according%20to%20Bloomberg). Baidu (like “Chinese Google” with its own AI) saw its big language model Ernie being used (at least in tests) by a PLA lab to train strategic combat scenarios​[scmp.com](https://www.scmp.com/news/china/science/article/3248050/chinas-military-lab-ai-connects-commercial-large-language-models-first-time-learn-more-about-humans#:~:text=According%20to%20scientists%20involved%20in,language%20models%20similar%20to%20ChatGPT). Baidu publicly denied any special partnership, saying its Ernie model is just what anyone can use online​[globaltimes.cn](https://www.globaltimes.cn/page/202401/1305446.shtml#:~:text=,used%20by%20the%20general%20public). But academics agree that Chinese “military-civil fusion” means innovations often hop quickly from industry to military use. China’s own analysts say AI could _“enable China to rapidly modernize its military, surpassing U.S. capabilities”_​[uscc.gov](https://www.uscc.gov/sites/default/files/2019-11/Chapter%203%20Section%202%20-%20Emerging%20Technologies%20and%20Military-Civil%20Fusion%20-%20Artificial%20Intelligence,%20New%20Materials,%20and%20New%20Energy.pdf#:~:text=%E2%80%A2%20Artificial%20intelligence%3A%20Chinese%20firms,and%20developing%20tactics%20that%20specifically), so the government pushes companies to help.
    

## Why This Matters for Education

You might wonder: _How does all this affect schools and learning?_ The answer is: **a lot**. First, it shapes how we teach AI ethics. Teachers need to explain that AI isn’t just for chatbots and translation—it’s also being used in war. Students should be aware that algorithms they study in class (like neural networks or language models) can have military applications. Without this context, public understanding of AI will be incomplete or naive.

 

Second, it affects trust in educational AI tools. If people know the same AI model is used by the military, they might worry about privacy and bias. For example, an AI tutor might use natural language technology similar to GPT. If families learn that GPT is also used in surveillance or weapon systems, they may distrust the tutor. EdTech companies can address this by being transparent: **“We use GPT-4 to grade essays. This same model also has been used in defense contexts, but our usage is strictly for education.”** Educators should also question whether an AI vendor has military contracts.

 

Third, the dual-use reality should shape the **design** of EdTech. System architects must include safety by design. For example, if a language model in a classroom can also generate realistic instructions, there should be blocks against producing violent or illegal content. Ongoing research called for “guardrails” (ethical constraints on AI behavior). Companies like OpenAI have content filters for ChatGPT; EdTech builders should adapt similar filters. It’s also wise to have _humans-in-the-loop_ when students use AI for important tasks (like college applications) – mirroring military practice of keeping a person in the decision chain to catch errors.

 

Fourth, this fusion pushes educators to push for better policies. Schools and universities could adopt clauses forbidding research funding from companies that sell weapons AI (analogous to “divestment” policies). Tech departments might require ethics courses. Professors working on open-source models should consider how to license them to discourage weapon use (as Meta tried, albeit imperfectly).

 

Finally, it influences _media literacy_. Students and the public must learn that technology isn’t value-neutral. AI in social media algorithms, search results, or even digital textbooks might be developed by the same teams that work with armies. Highlighting these connections helps learners become critical users of AI and advocates for responsible tech.

## Key Risks in Plain Terms

To wrap up, here are some clear risks that educators and technologists should watch:

- **Escalation of Conflict:** AI systems make decisions faster than humans. A glitch or misinterpretation could accidentally widen a conflict. Training our students in the humanities (history, ethics) alongside STEM helps them see that _technology won’t solve conflicts_ without wisdom.
    
- **Mistaken Identity:** No AI is perfect at recognizing faces or translating languages. If an AI mis-identifies a person as a threat, or mistranslates a conversation, lives are at stake. We see this in Gaza when systems “hallucinate” speech. In class, teachers could use examples (like Whisper adding fake phrases) to show AI’s limits.
    
- **Dual-Use Dilemma:** Many tools can be used for “good” or “bad.” Just like chemistry labs must handle chemicals carefully, AI courses should stress that “deployed responsibly” is not a given – it takes effort. We should teach students about **responsible AI**: who decides how a tool is used, and how to prevent misuse?
    
- **Erosion of Ethical Lines:** When tech companies change course from “AI only for good” to “AI for military,” it blurs the line of what’s acceptable. This shift can desensitize people (even developers) to the idea of AI in warfare. Education should counteract this by always asking _“Should this be done?”_ when discussing new tech.
    
- **Surveillance Creep:** Technologies developed for classroom analytics (like monitoring student engagement) could be adopted by governments for surveillance. If students learn about data ethics, they’ll be more vigilant about privacy.
    

## Recommendations for the Education Community

1. **Integrate AI Ethics Early:** Even in high school, students should learn about the dual-use nature of AI. For example, a project could be “Design an AI robot for education. Then discuss how the same design might be adapted for military use.” This encourages critical thinking.
    
2. **Promote Transparency:** Whenever a school or district considers an AI tool (like an automated grading system), ask: _Does this company have defense contracts?_ Students in civics or computer science classes can help investigate vendor claims. Having open dialogues in the classroom about these findings will raise awareness.
    
3. **Adopt Responsible AI Agreements:** Like doctors have a Hippocratic Oath, tech students could draft personal or community statements (e.g. “I will not create AI that harms humanity”). This reinforces personal responsibility. Universities could also pledge not to develop AI software for lethal autonomous weapons.
    
4. **Policy Advocacy:** Educators are trusted voices. They can push for regulations like banning fully autonomous “kill-switch” weapons (a debate already happening at the United Nations). Schools of education, engineering, and computer science should collaborate on policy statements, advising lawmakers on the educational impact of AI militarization.
    
5. **Interdisciplinary Courses:** Encourage joint courses between computer science and social sciences. Topics could include “AI in Society,” covering case studies (e.g. Project Maven protests, AI in drone warfare, censorship by AI in different regimes). These make clear that technology does not exist in a vacuum.
    
6. **Critical AI Literacy for All:** Finally, teach all students (not just future engineers) what AI is and isn’t. If the general public understands that the same algorithms can be used in warfare or healthcare, democratic oversight can improve. For younger students, this might mean simple lessons on “how would you feel if a robot graded your test – and what if that same robot was a soldier?”
    

By embedding awareness of the AI arms race into education, we prepare students to use and govern AI wisely. **The goal is not to forbid AI, but to ensure it serves peaceful, educational, and ethical ends.**

 

**Sources:** We drew on investigative journalism, official studies, and whistleblower reports to compile this guide. Key examples include Palantir’s military AI platform​[aimresearch.co](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=That%E2%80%99s%20not%20hyperbole,by%20Google%20after%20employee%20protests), Meta’s Llama model use in China​[reuters.com](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=Nov%201%20%28Reuters%29%20,three%20academic%20papers%20and%20analysts), OpenAI’s defense partnerships​[wired.com](https://www.wired.com/story/openai-anduril-defense/#:~:text=OpenAI%E2%80%99s%20AI%20models%20will%20be,pressure%20situations%2C%E2%80%9D%20he%20said)​[govconwire.com](https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/#:~:text=Using%20ChatGPT%20for%20%E2%80%9Cmilitary%20and,%E2%80%9D), Microsoft’s Israeli contracts​[apnews.com](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Israeli%20military%E2%80%99s%20usage%20of,months%20of%20the%20war%20alone)​[apnews.com](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20AP%20also%20interviewed%2014,and%20Israel%E2%80%99s%20Ministry%20of%20Defense), and China’s Huawei/Baidu military collaborations​[qz.com](https://qz.com/1653915/bloomberg-huawei-staff-did-ai-research-with-chinas-military#:~:text=Some%20employees%20of%20Chinese%20tech,satellite%20images%2C%20according%20to%20Bloomberg)​[scmp.com](https://www.scmp.com/news/china/science/article/3248050/chinas-military-lab-ai-connects-commercial-large-language-models-first-time-learn-more-about-humans#:~:text=According%20to%20scientists%20involved%20in,language%20models%20similar%20to%20ChatGPT). These sources underscore why educators must remain vigilant as AI technologies continue to advance on and off the battlefield.

Citations

[

![Favicon](https://www.google.com/s2/favicons?domain=https://aimresearch.co&sz=32)

Palantir Started By Spying on a City Now Sells AI for War

https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war

](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=That%E2%80%99s%20not%20hyperbole,by%20Google%20after%20employee%20protests)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aimresearch.co&sz=32)

Palantir Started By Spying on a City Now Sells AI for War

https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war

](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=But%20its%20client%20list%20and,makes%20decisions%20with%20lethal%20consequences)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aimresearch.co&sz=32)

Palantir Started By Spying on a City Now Sells AI for War

https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war

](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=In%202023%2C%20Immigration%20and%20Customs,one%20ICE%20official%20described%20it)[

![Favicon](https://www.google.com/s2/favicons?domain=https://aimresearch.co&sz=32)

Palantir Started By Spying on a City Now Sells AI for War

https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war

](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=Civil%20liberties%20groups%20call%20it,%E2%80%9D)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.reuters.com&sz=32)

Exclusive: Chinese researchers develop AI model for military use on back of Meta's Llama | Reuters

https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/

](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=Nov%201%20%28Reuters%29%20,three%20academic%20papers%20and%20analysts)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.reuters.com&sz=32)

Exclusive: Chinese researchers develop AI model for military use on back of Meta's Llama | Reuters

https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/

](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=,Reuters%20in%20a%20phone%20interview)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.theguardian.com&sz=32)

Meta to let US national security agencies and defense contractors use Llama AI | Artificial intelligence (AI) | The Guardian

https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai

](https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai#:~:text=Meta%20%20announced%20Monday%20that,wing%20of%20the%20Chinese%20government)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.theguardian.com&sz=32)

Meta to let US national security agencies and defense contractors use Llama AI | Artificial intelligence (AI) | The Guardian

https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai

](https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai#:~:text=Meta%E2%80%99s%20policies%20typically%20prohibit%20the,the%20UK%2C%20Canada%2C%20Australia%20and)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.theguardian.com&sz=32)

Meta to let US national security agencies and defense contractors use Llama AI | Artificial intelligence (AI) | The Guardian

https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai

](https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai#:~:text=%E2%80%9CThese%20kinds%20of%20responsible%20and,wrote%20in%20a%20blog%20post)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.govconwire.com&sz=32)

OpenAI Lifts Military Ban, Opens Doors to DOD for Cybersecurity Collab - GovCon Wire

https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/

](https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/#:~:text=At%20the%20World%20Economic%20Forum,based%20cybersecurity%20technology)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.govconwire.com&sz=32)

OpenAI Lifts Military Ban, Opens Doors to DOD for Cybersecurity Collab - GovCon Wire

https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/

](https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/#:~:text=Using%20ChatGPT%20for%20%E2%80%9Cmilitary%20and,%E2%80%9D)[

OpenAI Is Working With Anduril to Supply the US Military With AI | WIRED

https://www.wired.com/story/openai-anduril-defense/

](https://www.wired.com/story/openai-anduril-defense/#:~:text=OpenAI%E2%80%99s%20AI%20models%20will%20be,pressure%20situations%2C%E2%80%9D%20he%20said)[

OpenAI Is Working With Anduril to Supply the US Military With AI | WIRED

https://www.wired.com/story/openai-anduril-defense/

](https://www.wired.com/story/openai-anduril-defense/#:~:text=Anduril%20is%20developing%20an%20advanced,language%20models%20for%20testing%20purposes)[

OpenAI Is Working With Anduril to Supply the US Military With AI | WIRED

https://www.wired.com/story/openai-anduril-defense/

](https://www.wired.com/story/openai-anduril-defense/#:~:text=OpenAI%20Is%20Working%20With%20Anduril,the%20US%20Military%20With%20AI)[

![Favicon](https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32)

Project Nimbus - Wikipedia

https://en.wikipedia.org/wiki/Project_Nimbus

](https://en.wikipedia.org/wiki/Project_Nimbus#:~:text=The%20Israeli%20Finance%20Ministry%20,finance%2C%20healthcare)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Israeli%20military%20uses%20Microsoft,targeting%20systems%20and%20vice%20versa)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Microsoft%20data%20AP%20reviewed,racial%20commentary%20and%20violent%20rhetoric)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=As%20U,emerging%20technologies%20around%20the%20world)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20Israeli%20military%E2%80%99s%20usage%20of,months%20of%20the%20war%20alone)[

![Favicon](https://www.google.com/s2/favicons?domain=https://defensescoop.com&sz=32)

OpenAI's GPT-4o gets green light for top secret use in Microsoft's ...

https://defensescoop.com/2025/01/16/openais-gpt-4o-gets-green-light-for-top-secret-use-in-microsofts-azure-cloud/

](https://defensescoop.com/2025/01/16/openais-gpt-4o-gets-green-light-for-top-secret-use-in-microsofts-azure-cloud/#:~:text=,US%20Government%20Top%20Secret%20cloud)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20AP%20also%20interviewed%2014,and%20Israel%E2%80%99s%20Ministry%20of%20Defense)[

![Favicon](https://www.google.com/s2/favicons?domain=https://qz.com&sz=32)

Bloomberg: Huawei staff did AI research with China's military

https://qz.com/1653915/bloomberg-huawei-staff-did-ai-research-with-chinas-military

](https://qz.com/1653915/bloomberg-huawei-staff-did-ai-research-with-chinas-military#:~:text=Some%20employees%20of%20Chinese%20tech,satellite%20images%2C%20according%20to%20Bloomberg)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.scmp.com&sz=32)

China’s military lab AI connects to commercial large language models for the first time to learn more about humans | South China Morning Post

https://www.scmp.com/news/china/science/article/3248050/chinas-military-lab-ai-connects-commercial-large-language-models-first-time-learn-more-about-humans

](https://www.scmp.com/news/china/science/article/3248050/chinas-military-lab-ai-connects-commercial-large-language-models-first-time-learn-more-about-humans#:~:text=According%20to%20scientists%20involved%20in,language%20models%20similar%20to%20ChatGPT)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.uscc.gov&sz=32)

https://www.uscc.gov/sites/default/files/2019-11/Chapter%203%20Section%202%20-%20Emerging%20Technologies%20and%20Military-Civil%20Fusion%20-%20Artificial%20Intelligence,%20New%20Materials,%20and%20New%20Energy.pdf

](https://www.uscc.gov/sites/default/files/2019-11/Chapter%203%20Section%202%20-%20Emerging%20Technologies%20and%20Military-Civil%20Fusion%20-%20Artificial%20Intelligence,%20New%20Materials,%20and%20New%20Energy.pdf#:~:text=%E2%80%A2%20Artificial%20intelligence%3A%20Chinese%20firms,and%20developing%20tactics%20that%20specifically)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.reuters.com&sz=32)

Exclusive: Chinese researchers develop AI model for military use on back of Meta's Llama | Reuters

https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/

](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=However%2C%20because%20Meta%27s%20models%20are,ways%20of%20enforcing%20those%20provisions)[

![Favicon](https://www.google.com/s2/favicons?domain=https://unidir.org&sz=32)

[PDF] Global Conference on AI, Security and Ethics - UNIDIR

https://unidir.org/wp-content/uploads/2025/04/AISE25_posters.pdf

](https://unidir.org/wp-content/uploads/2025/04/AISE25_posters.pdf#:~:text=Ethical%20dilemmas.%20AI,escalation%2C%20bias%2C%20errors%20and%20malfunctions)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=military%20has%20made%20heavy%20use,racial%20commentary%20and%20violent%20rhetoric)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.reuters.com&sz=32)

Exclusive: Chinese researchers develop AI model for military use on back of Meta's Llama | Reuters

https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/

](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=U,of%20safeguards%20within%20the%20model)[

![Favicon](https://www.google.com/s2/favicons?domain=https://apnews.com&sz=32)

How US tech giants' AI is changing the face of warfare in Gaza and Lebanon | AP News

https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108

](https://apnews.com/article/israel-palestinians-ai-technology-737bc17af7b03e98c29cec4e15d0f108#:~:text=The%20AP%20also%20interviewed%2014,and%20Israel%E2%80%99s%20Ministry%20of%20Defense)[

![Favicon](https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32)

Project Nimbus - Wikipedia

https://en.wikipedia.org/wiki/Project_Nimbus

](https://en.wikipedia.org/wiki/Project_Nimbus#:~:text=Although%20Project%20Nimbus%27%20specific%20mission,1)[

OpenAI Is Working With Anduril to Supply the US Military With AI | WIRED

https://www.wired.com/story/openai-anduril-defense/

](https://www.wired.com/story/openai-anduril-defense/#:~:text=A%20few%20years%20ago%2C%20many,backed%20out%20of%20the%20project)[

Baidu strongly denies rumor of link between its AI tool and China’s military research - Global Times

https://www.globaltimes.cn/page/202401/1305446.shtml

](https://www.globaltimes.cn/page/202401/1305446.shtml#:~:text=,used%20by%20the%20general%20public)

All Sources

[

![Favicon](https://www.google.com/s2/favicons?domain=https://aimresearch.co&sz=32)aimresearch

](https://aimresearch.co/ai-startups/palantir-started-by-spying-on-a-city-now-sells-ai-for-war#:~:text=That%E2%80%99s%20not%20hyperbole,by%20Google%20after%20employee%20protests)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.reuters.com&sz=32)reuters

](https://www.reuters.com/technology/artificial-intelligence/chinese-researchers-develop-ai-model-military-use-back-metas-llama-2024-11-01/#:~:text=Nov%201%20%28Reuters%29%20,three%20academic%20papers%20and%20analysts)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.theguardian.com&sz=32)theguardian

](https://www.theguardian.com/technology/2024/nov/05/meta-allows-national-security-defense-contractors-use-llama-ai#:~:text=Meta%20%20announced%20Monday%20that,wing%20of%20the%20Chinese%20government)[

![Favicon](https://www.google.com/s2/favicons?domain=https://www.govconwire.com&sz=32)govconwire

](https://www.govconwire.com/2024/01/openai-lifts-military-ban-opens-doors-to-dod-for-cybersecurity-collab/#:~:text=At%20the%20World%20Economic%20Forum,based%20cybersecurity%20technology)[

wired

](https://www.wired.com/story/openai-anduril-defense/#:~:text=OpenAI%E2%80%99s%20AI%20models%20will%20be,pressure%20situations%2C%E2%80%9D%20he%20said)[

![Favicon](https://www.google.com/s2/favicons?domain=https://en.wikipedia.org&sz=32)en.wikip

](https://en.wikipedia.org/wiki/Project_Nimbus#:~:text=The%20Israeli%20Finance%20Ministry%20,finance%2C%20healthcare)